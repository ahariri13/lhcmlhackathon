{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple4layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ezrc1g0Mz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTI6u5Vz0M0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size  = 180000     # Training size\n",
        "valid_size  = 50000    # Validation size\n",
        "#test_size   = 10000     # Test size\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUn_iYm00M0K",
        "colab_type": "code",
        "outputId": "8ad0604c-67c5-438a-ed83-cf8b97ee8552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    \n",
        "# move the model to GPU, if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvO-puPH0M0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6KhywZ-0M0b",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUwb25Ot0M0d",
        "colab_type": "code",
        "outputId": "9558d286-ebd7-47a9-d85d-5f92e64dbabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"/content/drive/My Drive/lhcmlhackathon-master/notebooks/\"\n",
        "\n",
        "img_rows, img_cols, nb_channels = 32, 32, 2        \n",
        "input_dir = 'data'\n",
        "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n",
        "\n",
        "def load_data(decays, start, stop):\n",
        "    global input_dir\n",
        "    dsets = [h5py.File(filepath+'%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
        "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
        "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
        "    assert len(X) == len(y)\n",
        "    return X, y"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO1nlbYr0tbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi16-NkW0M0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set range of training set\n",
        "train_start, train_stop = 0, train_size\n",
        "assert train_stop > train_start\n",
        "assert (len(decays)*train_size) % batch_size == 0\n",
        "X_train, y_train = load_data(decays,train_start,train_stop)\n",
        "\n",
        "# Set range of validation set\n",
        "valid_start, valid_stop = train_size, train_size+valid_size\n",
        "assert valid_stop  >  valid_start\n",
        "assert valid_start >= train_stop\n",
        "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
        "'''\n",
        "# Set range of test set\n",
        "test_start, test_stop = 204800, 204800+test_size\n",
        "assert test_stop  >  test_start\n",
        "assert test_start >= valid_stop\n",
        "X_test, y_test = load_data(decays,test_start,test_stop)\n",
        "'''\n",
        "samples_requested = len(decays) * (train_size + valid_size )#+ test_size)\n",
        "samples_available = len(y_train) + len(y_valid) #+ len(y_test)\n",
        "assert samples_requested == samples_available"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFldUwry6Z77",
        "colab_type": "code",
        "outputId": "f22169b7-7bd8-48ca-80a3-47c7e3bb2b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape,y_valid.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360000,), (100000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM3TTq2Z0M0j",
        "colab_type": "code",
        "outputId": "6e0091d1-d3ac-4dd9-842b-0063d17d57cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "plt.figure(1)\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0,:,:,0])\n",
        "plt.title(\"Channel 0\")  # Energy\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[0,:,:,1])\n",
        "plt.title(\"Channel 1\")  # Time\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAACSCAYAAADckaYRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq7gG_EX0M0p",
        "colab_type": "code",
        "outputId": "119f7198-da85-4478-fb31-2f8290affc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape,X_valid.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360000, 32, 32, 2), (100000, 32, 32, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZZoto250M0s",
        "colab_type": "code",
        "outputId": "7f784986-fafa-4e7a-fe59-56d8028f486a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBF7JLMu0M0x",
        "colab_type": "code",
        "outputId": "ff5e7e52-0bf6-414e-82a0-593b1e144858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].T.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC2veVnp0M00",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keQDlBOK0M01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Custom Dataset\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfqq7WxQ0M04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DataTrain(Dataset):\n",
        "    def __init__(self):\n",
        "        super(DataTrain, self).__init__()\n",
        "        ############ Transforms\n",
        "        #normalize\n",
        "        #transforms.Normalize((0.5, 0.5), (0.25, 0.25))\n",
        "        #transforms.CenterCrop(224),\n",
        "        #torchvision.transforms.RandomHorizontalFlip(),\n",
        "        #torchvision.transforms.RandomRotation(10),\n",
        "        \n",
        "\n",
        "        ############ data\n",
        "        self.data = torch.Tensor(X_train).float()\n",
        "        self.labels = torch.Tensor(y_train).long()\n",
        "        \n",
        "    def __getitem__(self, index):  #get 1 jet tracks\n",
        "        ########### input\n",
        "        image = torch.transpose(self.data[index],0,-1)\n",
        "  \n",
        "        ########### label\n",
        "        data_label = self.labels[index]\n",
        "        #data_label = data_label.view(1,1) ## each element needs torch.Size = 1\n",
        "        return image,data_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0] # number of jets\n",
        "    \n",
        "    \n",
        "class DataValid(Dataset):\n",
        "    def __init__(self):\n",
        "        super(DataValid, self).__init__()\n",
        "        ############ Transforms\n",
        "        #normalize\n",
        "        #transforms.Normalize((0.5, 0.5), (0.25, 0.25))\n",
        "        ############ data\n",
        "        self.data = torch.Tensor(X_valid).float()\n",
        "        self.labels = torch.Tensor(y_valid).long()\n",
        "        \n",
        "    def __getitem__(self, index):  #get 1 jet tracks\n",
        "        ########### input\n",
        "        image = torch.transpose(self.data[index],0,-1)\n",
        "  \n",
        "        ########### label\n",
        "        data_label = self.labels[index]\n",
        "        #data_label = data_label.view(1,1) ## each element needs torch.Size = 1\n",
        "        return image,data_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0] # number of jets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egEIaODX0M06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchSize = 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EgUMv080M07",
        "colab_type": "code",
        "outputId": "6d92c997-571b-4883-e02f-39320728c682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "DataTrain_ = DataTrain()\n",
        "DataValid_ = DataValid()\n",
        "\n",
        "DataTrainLoader = DataLoader(dataset = DataTrain_,batch_size = batchSize ,shuffle = True,drop_last=True, pin_memory = False) #num_workers=4 #number of cpu workers\n",
        "DataValidLoader = DataLoader(dataset = DataValid_,batch_size = batchSize ,shuffle = True,drop_last=True, pin_memory = False)\n",
        "\n",
        "print(len(DataTrain_)) #number of jets\n",
        "len(DataTrainLoader) #number of batches of jets"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HH2Elyf0M0-",
        "colab_type": "code",
        "outputId": "a0ce813b-7146-456c-a93f-082e999e3ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.array([[[1,2],[2,3],[4,5]]])\n",
        "b = torch.tensor(a)\n",
        "b.shape, torch.transpose(b,0,-1).shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 2]), torch.Size([2, 3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB02FwzU0M1A",
        "colab_type": "text"
      },
      "source": [
        "## Build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNLKcdc70M1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaRrQJJS0M1C",
        "colab_type": "code",
        "outputId": "d4870ac2-4a8c-49f0-8036-2aac05da92b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 32x32x2 image tensor)\n",
        "        self.conv1 = nn.Conv2d(2, 16, 2, padding=0)\n",
        "        # convolutional layer (sees 16x16x16 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, padding=0)\n",
        "        # convolutional layer (sees 8x8x32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2, padding=0)\n",
        "        # convolutional layer (sees 4x4x64 tensor)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 2, padding=0)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (64 * 4 * 4 -> 500)\n",
        "        self.fc1 = nn.Linear(64 * 2 , 500)\n",
        "        # linear layer (500 -> 2)\n",
        "        self.fc2 = nn.Linear(500, 256)\n",
        "        self.fc3 = nn.Linear(256,128)\n",
        "        self.fc4 = nn.Linear(128,64)\n",
        "        self.fc5 = nn.Linear(64,32)\n",
        "        self.fc6 = nn.Linear(32,16)\n",
        "        self.fc7 = nn.Linear(16,2)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        #print(x.shape)\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 64 * 2 )\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.dropout(x)        \n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc6(x))\n",
        "        x = self.dropout(x)        \n",
        "        x = self.fc7(x)\n",
        "        return x.reshape(batchSize,x.shape[1])\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(2, 16, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=128, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (fc7): Linear(in_features=16, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMLNiucm0M1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function \n",
        "#criterion = nn.NLLLoss()\n",
        "criterion =nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPRzNFg90M1I",
        "colab_type": "code",
        "outputId": "b4efe9a8-1d8b-4016-859c-bed71aa0bc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        }
      },
      "source": [
        "######## first check\n",
        "# obtain one batch of training set\n",
        "dataiter = iter(DataTrainLoader)\n",
        "data_tr,data_l = dataiter.next()\n",
        "\n",
        "######## Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "print(data_tr.shape,data_l.shape)\n",
        "\n",
        "###### move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "  data_tr = data_tr.cuda()\n",
        "  data_l = data_l.cuda()\n",
        "\n",
        "####### Forward pass, then backward pass, then update weights\n",
        "output = model(data_tr)\n",
        "loss = criterion(output, data_l)\n",
        "loss.backward()\n",
        "print(torch.softmax(output,1))\n",
        "print(loss.item())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 2, 32, 32]) torch.Size([64])\n",
            "tensor([[0.6032, 0.3968],\n",
            "        [0.6030, 0.3970],\n",
            "        [0.6048, 0.3952],\n",
            "        [0.6113, 0.3887],\n",
            "        [0.5954, 0.4046],\n",
            "        [0.5944, 0.4056],\n",
            "        [0.5913, 0.4087],\n",
            "        [0.6057, 0.3943],\n",
            "        [0.6110, 0.3890],\n",
            "        [0.5865, 0.4135],\n",
            "        [0.5977, 0.4023],\n",
            "        [0.6007, 0.3993],\n",
            "        [0.5983, 0.4017],\n",
            "        [0.6046, 0.3954],\n",
            "        [0.5901, 0.4099],\n",
            "        [0.5978, 0.4022],\n",
            "        [0.5976, 0.4024],\n",
            "        [0.5994, 0.4006],\n",
            "        [0.6011, 0.3989],\n",
            "        [0.5960, 0.4040],\n",
            "        [0.6005, 0.3995],\n",
            "        [0.5953, 0.4047],\n",
            "        [0.6117, 0.3883],\n",
            "        [0.6089, 0.3911],\n",
            "        [0.6062, 0.3938],\n",
            "        [0.5870, 0.4130],\n",
            "        [0.6091, 0.3909],\n",
            "        [0.5931, 0.4069],\n",
            "        [0.5882, 0.4118],\n",
            "        [0.6021, 0.3979],\n",
            "        [0.6101, 0.3899],\n",
            "        [0.6120, 0.3880],\n",
            "        [0.5954, 0.4046],\n",
            "        [0.5978, 0.4022],\n",
            "        [0.6000, 0.4000],\n",
            "        [0.6071, 0.3929],\n",
            "        [0.5992, 0.4008],\n",
            "        [0.6042, 0.3958],\n",
            "        [0.5934, 0.4066],\n",
            "        [0.6052, 0.3948],\n",
            "        [0.5972, 0.4028],\n",
            "        [0.5986, 0.4014],\n",
            "        [0.6049, 0.3951],\n",
            "        [0.6143, 0.3857],\n",
            "        [0.6080, 0.3920],\n",
            "        [0.5976, 0.4024],\n",
            "        [0.6170, 0.3830],\n",
            "        [0.5901, 0.4099],\n",
            "        [0.6136, 0.3864],\n",
            "        [0.5998, 0.4002],\n",
            "        [0.5950, 0.4050],\n",
            "        [0.5977, 0.4023],\n",
            "        [0.5945, 0.4055],\n",
            "        [0.6007, 0.3993],\n",
            "        [0.6007, 0.3993],\n",
            "        [0.5994, 0.4006],\n",
            "        [0.5987, 0.4013],\n",
            "        [0.6007, 0.3993],\n",
            "        [0.5980, 0.4020],\n",
            "        [0.6138, 0.3862],\n",
            "        [0.6012, 0.3988],\n",
            "        [0.5986, 0.4014],\n",
            "        [0.5892, 0.4108],\n",
            "        [0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "0.6795428991317749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebDdBJVD0M1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = Net()\n",
        "#model.load_state_dict(torch.load(\"/content/drive/My Drive/lhcmlhackathon-master/notebooks/model.pt\"),strict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uip0yqy50M1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8OxvbxR0M1N",
        "colab_type": "code",
        "outputId": "73be1a38-43e0-430c-c47f-268e5be85023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 1\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy_train = 0\n",
        "    accuracy_valid = 0\n",
        "    predicted_labels_score = []\n",
        "    labels = []\n",
        "    equal = []\n",
        "    eqs = []\n",
        "    ps_ = []\n",
        "    target_scores = []\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in DataTrainLoader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "        \n",
        "        #### training accuracy\n",
        "        ps = torch.softmax(output,dim = 1)\n",
        "        #print(ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        accuracy_train += torch.mean(equals.type(torch.FloatTensor))   \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in DataValidLoader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "        \n",
        "        #### valid accuracy\n",
        "        ps = torch.softmax(output,dim = 1)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        \n",
        "        target_scores.append(ps.cpu().detach().numpy()[target.cpu().detach().numpy()])\n",
        "        predicted_labels_score.append(top_p.cpu().detach().numpy())\n",
        "        labels.append(target.cpu().detach().numpy())\n",
        "        a = np.concatenate(labels)\n",
        "        equal.append(equals.cpu().detach().numpy())\n",
        "        ps_.append(ps.cpu().detach().numpy()[:,1])\n",
        "\n",
        "        \n",
        "        \n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        \n",
        "        \n",
        "        accuracy_valid += torch.mean(equals.type(torch.FloatTensor))   \n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(DataTrainLoader)\n",
        "    valid_loss = valid_loss/len(DataValidLoader)\n",
        "    \n",
        "    accuracy_train = accuracy_train/len(DataTrainLoader)\n",
        "    accuracy_valid =  accuracy_valid/len(DataValidLoader)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    #print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "    #    epoch, train_loss, valid_loss))\n",
        "    print('Epoch: {} \\tTraining acc: {:.6f} \\tValidation acc: {:.6f}'.format(\n",
        "        epoch, accuracy_train, accuracy_valid))\n",
        "\n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining acc: 0.714997 \tValidation acc: 0.716489\n",
            "Validation loss decreased (inf --> 36.023099).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-3_8cPT_sH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.concatenate(np.asarray(ps_)); b = np.concatenate(np.asarray(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y03yB15NRYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9633f12f-76dd-4f4e-d003-b4a34911d233"
      },
      "source": [
        "roc_auc_score(b,a)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7806147691662977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Q_Ue_DNlAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}